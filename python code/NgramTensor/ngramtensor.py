
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import csv
import sys
import re
import os


import numpy as np


"""
File reads in txt file generated by ngrams program and convert this into a csv file
This csv file can then be read by tensorlab.

The reason for doing this is that tensorlab has tensor decomposition functions built in, while tensorflow
does not.
"""

data_path = "../../testData/Win/"


def dec(hexVal):
    return int(hexVal, 16)


def create_ngram_tensor(filename):
    line_no= 1

    '''
    show the occurences of 1-grams in the given file
    '''
    current_ngram = 1
    ngram_one = np.zeros((16,16), int)
    ngram_two = np.zeros((16,16,16,16), int) #create_4d_16()
    #ngram_three = np.zeros((16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16), int) Needs to be run on a machine with more RAM

    with open(filename, 'r') as f:
        ngram_count = 1
        for line in f:
            if line_no >= 4:
                if line == "":
                    break
                else:
                    if line.startswith("1-GRAMS"):
                        m = re.search('(\d+)(?!.*\d)', line)
                        ngram_count = int(m.group(0))
                        print("1-GRAM ngram count", ngram_count)
                        current_ngram = 1
                    if line.startswith("2-GRAMS"):
                        m = re.search('(\d+)(?!.*\d)', line)
                        ngram_count = int(m.group(0))
                        print(ngram_count)
                        current_ngram = 2
                    elif line.startswith("3-GRAMS"):
                        current_ngram = 3
                        break
                    split_line = line.split()

                    if len(split_line) == 2:
                        word = split_line[0]
                        ngram = list(word)
                        frequency = int(split_line[1])
                        if current_ngram == 1:
                            ngram_one[int(ngram[0], 16)][int(ngram[1], 16)] = (1.0*frequency)#/ngram_count
                            #print("frequency is " + str((100.0*frequency)/ngram_count))
                        elif current_ngram == 2:
                            ngram_two[dec(ngram[0])][dec(ngram[1])][dec(ngram[2])][dec(ngram[3])] = (1.0*frequency)#/ngram_count
                        else:
                            break

            line_no += 1
    return ngram_one, ngram_two

def create_average_tensor(directory):
    ngram_one_total = []
    ngram_two_total = []
    files = 0.0
    for filename in os.listdir(directory):
        if filename.endswith(".gram"):
            files += 1
            ngram_one, ngram_two = create_ngram_tensor(directory + filename)
            if ngram_one_total != []:
                ngram_one_total += ngram_one
                ngram_two_total += ngram_two
            else:
                ngram_one_total = ngram_one
                ngram_two_total = ngram_two

    ngram_one = ngram_one_total / files
    ngram_two = ngram_two_total / files
    return ngram_one, ngram_two


def save_tensors(ngram_one, ngram_two, file):
    with open(data_path + file + "ngram_two.csv", 'w') as file:
        csv_file = csv.writer(file)
        for i in range(16):
            for j in range(16):
                csv_file.writerows(ngram_two[i][j])
    print(len(ngram_two[0]))


def normalize_tensors(ngram_one, ngram_two):
    ngram_one = [i / sum(ngram_one) for i in ngram_one]
    ngram_two = ngram_two / np.sum(ngram_two)
    ngram_one = np.asarray(ngram_one)
    return ngram_one, ngram_two

def main():
    file = ""
    if len(sys.argv) < 2:
        print("Please provide an option")
        print("Use -av for average of files in data path")
        print("Use -f to read in files")
        exit
    option = sys.argv[1]

    if option == "-av":
        ngram_one, ngram_two = create_average_tensor(data_path)

        file = "average"
    else:
        for i in range(1, len(sys.argv)):
            file = sys.argv[i]
            print(data_path + file)
            ngram_one, ngram_two = create_ngram_tensor(data_path + file)

    ngram_one, ngram_two = normalize_tensors(ngram_one, ngram_two)
    save_tensors(ngram_two, ngram_two, file)
    np.savetxt(data_path + file + "ngram_one.csv", ngram_one, delimiter=",")



if __name__ == '__main__':
    main()


